# QCC 5

1. What is the big issue that we're examining from a fairness perspective and who are the relevant stakeholders? 

According to Professor Hutchins, when there is not fairness present, discrimination occurs, such as an algorithm unfairly judging a person or action based on their skin color or class rather than their talents. 

2. What are the procedures and outcomes that relate the stakeholders to this issue? 

In the case of discriminatory artificial intelligence, it is possible that humans can be judged by their previous achievements rather than stereotypes/first impressions using non-biased AI. 

3. Are the procedures formally fair? In other words, are the same procedures followed for the relevant stakeholders? 

No, since if humans were to judge instead of AI, there would be an even bigger, harder-to-fix risk of unfairness in results. 

4. Are the procedures substantively fair? For example, is there something interfering with some stakeholders' outcomes but not others? 

No, since algorithms can "learn" to be unfair through processes disguised by efficiency and machine learning. 

5. What would you recommend based on this analysis of fairness? 

You should use programmers from different classes and races to help program, and should not judge at all based on ethnicity and cultural background. 